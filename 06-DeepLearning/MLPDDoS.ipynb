{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2916704",
   "metadata": {},
   "source": [
    "# Intrusion Detection con Multi-Layer Perceptron (MLP)\n",
    "In questo notebook utilizzeremo una rete neurale MLP per classificare i flussi di traffico di rete come benigni o dannosi. Il modello di MLP restituisce un valore compreso tra 0 e 1, che rappresenta la probabilità che il flusso in ingresso sia dannoso. Usiamo una soglia fissata a 0,5 per determinare se il flusso di rete è dannoso o meno.\n",
    "Addestreremo un modello di Logistic Regression con traffico di rete benigno e quattro classi di attacchi DDoS dal dataset CIC-DDoS2019 dell’Università del New Brunswick. Il traffico di rete è stato precedentemente pre-elaborato in modo che i pacchetti siano raggruppati in flussi di traffico bidirezionali utilizzando la 5-tupla (IP sorgente, IP destinazione, porta sorgente, porta destinazione, protocollo). Ogni flusso è rappresentato da 21 features (attributi) dell’header dei pacchetti calcolate da un massimo di 1000 pacchetti:\n",
    "\n",
    "| Features           | Multi-Layer Perceptron          |\n",
    "|---------------------|--------------------|\n",
    "| timestamp (mean IAT)  <br> packet_length (mean) <br> IP_flags_df (sum) <br> IP_flags_mf (sum) <br> IP_flags_rb (sum) <br> IP_frag_off (sum) <br> protocols (mean) <br> TCP_length (mean) <br> TCP_flags_ack (sum) <br> TCP_flags_cwr (sum) <br> TCP_flags_ece (sum) <br> TCP_flags_fin (sum) <br> TCP_flags_push (sum) <br> TCP_flags_res (sum) <br> TCP_flags_reset (sum) <br> TCP_flags_syn (sum) <br> TCP_flags_urg (sum) <br> TCP_window_size (mean) <br> UDP_length (mean) <br> ICMP_type (mean) <br> Packets (counter) <br>| <img src=\"./MLP.jpg\" width=\"100%\">  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a046372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Corso di Algoritmi di Machine Learning per la rilevazione di attacchi informatici\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import time\n",
    "from util_functions import *\n",
    "DATASET_FOLDER = \"../Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf328a43",
   "metadata": {},
   "source": [
    "# Conversione delle labels\n",
    "Nel nostro dataset, le labels assegnate ai flussi hanno un valore numerico che varia da 0 (benigno) a 4 (abbiamo 4 tipi di attacchi). In questo notebook, noi ci occupiamo di classificazione binaria (0/1, cioe' benigno/malevolo) e per cui, dopo aver caricato il dataset dai files, convertiamo tutte le labels > 0 in 1. \n",
    "\n",
    "Questo vuol dire che non ci interessa capire il tipo di attacco, ma solo se c'e' un attacco o meno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc165dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training, validation and test sets\n",
    "feature_names = get_feature_names()\n",
    "target_names = ['benign', 'dns',  'syn', 'udplag', 'webddos'] \n",
    "\n",
    "X_train, y_train = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5')\n",
    "y_train = np.array([1 if y > 0 else 0 for y in y_train]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1\n",
    "\n",
    "X_val, y_val = load_dataset(DATASET_FOLDER + \"/*\" + '-val.hdf5')\n",
    "y_val = np.array([1 if y > 0 else 0 for y in y_val]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1\n",
    "\n",
    "X_test, y_test = load_dataset(DATASET_FOLDER + \"/*\" + '-test.hdf5')\n",
    "y_test = np.array([1 if y > 0 else 0 for y in y_test]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bf8f4",
   "metadata": {},
   "source": [
    "# Implementazione del modello\n",
    "Nella prossima cella, implementiamo il modello MLP. \n",
    "Il modello e' creato partendo dal modello di Logistic regression al quale aggiungiamo un numero configurabile di ```hidden_layers``` e ```hidden_units```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "def create_model(hidden_layers=0, hidden_units=1):\n",
    "    model = Sequential(name  = \"mlp\")\n",
    "    # Questo e' l'input layer. In questo caso abbiamo 21 features\n",
    "    model.add(Input(shape=(21,)))\n",
    "    \n",
    "    # I seguenti sono gli hidden layers\n",
    "    for layer in range(hidden_layers):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "    \n",
    "    # Infine l'output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff22587",
   "metadata": {},
   "source": [
    "# Model training con Grid Search e Early Stopping\n",
    "Il codice nella cella seguente esegue la configurazione automatica del modello MLP con la strategia ```grid search```.\n",
    "Grid Search è una tecnica di ottimizzazione dei parametri dei modelli di Deep Learning (ma anche di modelli di Machine Learning) che consiste nella ricerca sistematica della combinazione ottimale di parametri (per esempio, hidden layers e hidden units (neuroni)), valutando le prestazioni di un modello su una griglia di possibili valori di questi parametri. La griglia dei parametri è  definita dal programmatore. \n",
    "\n",
    "Il tuo compito e' di inserire alcuni valori nella griglia sotto e di far partire l'addestramento del modello MLP.\n",
    "Assegna anche un valore di ```PATIENCE``` assegnando un numero intero alla variabile ```PATIENCE```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KerasClassifier based on the create_model function\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=100, verbose=1)\n",
    "\n",
    "### Inserisci alcuni valori interi separati da virgola tra le parentesi quadre ####\n",
    "param_grid = {\n",
    "    'hidden_layers' : [],\n",
    "    'hidden_units' : []\n",
    "}\n",
    "###########################################################\n",
    "\n",
    "### Stabilisci il valore di PATIENCE (per esempio 10) ###\n",
    "PATIENCE = \n",
    "###########################################################\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n",
    "\n",
    "### Add early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE, restore_best_weights=True)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks= [early_stopping])\n",
    "stop_time = time.time()\n",
    "\n",
    "# Total training time\n",
    "print(\"Total training time (sec): \", stop_time-start_time)\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters found: \", grid_result.best_params_)\n",
    "print(\"Best cross-validated accuracy: {:.2f}\".format(grid_result.best_score_))\n",
    "\n",
    "# Salviamo il modello migliore\n",
    "best_model = grid.best_estimator_.model\n",
    "best_model.save('./mlp_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53ac0a",
   "metadata": {},
   "source": [
    "# Usiamo il modello con dei dati mai visti (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62517926",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.squeeze(best_model.predict(X_test, batch_size=32) > 0.5)\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e91998",
   "metadata": {},
   "source": [
    "# Stampiamo la confusion matrix\n",
    "Questo ci permette di capire dove sbaglia il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "y_test_binary = (y_test > 0).astype(int)\n",
    "y_pred_binary = (y_pred > 0).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['Benigno', 'DDoS'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
