{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2916704",
   "metadata": {},
   "source": [
    "# Intrusion Detection con Multi-Layer Perceptron (MLP)\n",
    "In questo notebook utilizzeremo una rete neurale MLP per classificare i flussi di traffico di rete come benigni o dannosi. Il modello di MLP restituisce un valore compreso tra 0 e 1, che rappresenta la probabilità che il flusso in ingresso sia dannoso. Usiamo una soglia fissata a 0,5 per determinare se il flusso di rete è dannoso o meno.\n",
    "Addestreremo un modello di Logistic Regression con traffico di rete benigno e quattro classi di attacchi DDoS dal dataset CIC-DDoS2019 dell’Università del New Brunswick. Il traffico di rete è stato precedentemente pre-elaborato in modo che i pacchetti siano raggruppati in flussi di traffico bidirezionali utilizzando la 5-tupla (IP sorgente, IP destinazione, porta sorgente, porta destinazione, protocollo). Ogni flusso è rappresentato da 21 features (attributi) dell’header dei pacchetti calcolate da un massimo di 1000 pacchetti:\n",
    "\n",
    "| Features           | Multi-Layer Perceptron          |\n",
    "|---------------------|--------------------|\n",
    "| timestamp (mean IAT)  <br> packet_length (mean) <br> IP_flags_df (sum) <br> IP_flags_mf (sum) <br> IP_flags_rb (sum) <br> IP_frag_off (sum) <br> protocols (mean) <br> TCP_length (mean) <br> TCP_flags_ack (sum) <br> TCP_flags_cwr (sum) <br> TCP_flags_ece (sum) <br> TCP_flags_fin (sum) <br> TCP_flags_push (sum) <br> TCP_flags_res (sum) <br> TCP_flags_reset (sum) <br> TCP_flags_syn (sum) <br> TCP_flags_urg (sum) <br> TCP_window_size (mean) <br> UDP_length (mean) <br> ICMP_type (mean) <br> Packets (counter) <br>| <img src=\"./MLP.jpg\" width=\"100%\">  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a046372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Corso di Algoritmi di Machine Learning per la rilevazione di attacchi informatici\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import time\n",
    "from util_functions import *\n",
    "DATASET_FOLDER = \"../Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf328a43",
   "metadata": {},
   "source": [
    "# Conversione delle labels\n",
    "Nel nostro dataset, le labels assegnate ai flussi hanno un valore numerico che varia da 0 (benigno) a 4 (abbiamo 4 tipi di attacchi). In questo notebook, noi ci occupiamo di classificazione binaria (0/1, cioe' benigno/malevolo) e per cui, dopo aver caricato il dataset dai files, convertiamo tutte le labels > 0 in 1. \n",
    "\n",
    "Questo vuol dire che non ci interessa capire il tipo di attacco, ma solo se c'e' un attacco o meno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cc165dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training, validation and test sets\n",
    "feature_names = get_feature_names()\n",
    "target_names = ['benign', 'dns',  'syn', 'udplag', 'webddos'] \n",
    "\n",
    "X_train, y_train = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5')\n",
    "y_train = np.array([1 if y > 0 else 0 for y in y_train]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1\n",
    "\n",
    "X_val, y_val = load_dataset(DATASET_FOLDER + \"/*\" + '-val.hdf5')\n",
    "y_val = np.array([1 if y > 0 else 0 for y in y_val]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1\n",
    "\n",
    "X_test, y_test = load_dataset(DATASET_FOLDER + \"/*\" + '-test.hdf5')\n",
    "y_test = np.array([1 if y > 0 else 0 for y in y_test]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bf8f4",
   "metadata": {},
   "source": [
    "# Implementazione del modello\n",
    "Nella prossima cella, implementiamo il modello MLP. \n",
    "Il modello e' creato partendo dal modello di Logistic regression al quale aggiungiamo un numero configurabile di ```hidden_layers``` e ```hidden_units```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f44e3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "def create_model(hidden_layers=0, hidden_units=1):\n",
    "    model = Sequential(name  = \"mlp\")\n",
    "    # Questo e' l'input layer. In questo caso abbiamo 21 features\n",
    "    model.add(Input(shape=(21,)))\n",
    "    \n",
    "    # I seguenti sono gli hidden layers\n",
    "    for layer in range(hidden_layers):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "    \n",
    "    # Infine l'output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff22587",
   "metadata": {},
   "source": [
    "# Model training con Grid Search e Early Stopping\n",
    "Il codice nella cella seguente esegue la configurazione automatica del modello MLP con la strategia ```grid search```.\n",
    "Grid Search è una tecnica di ottimizzazione dei parametri dei modelli di Deep Learning (ma anche di modelli di Machine Learning) che consiste nella ricerca sistematica della combinazione ottimale di parametri (per esempio, hidden layers e hidden units (neuroni)), valutando le prestazioni di un modello su una griglia di possibili valori di questi parametri. La griglia dei parametri è  definita dal programmatore. \n",
    "\n",
    "Il tuo compito e' di inserire alcuni valori nella griglia sotto e di far partire l'addestramento del modello MLP.\n",
    "Assegna anche un valore di ```PATIENCE``` assegnando un numero intero alla variabile ```PATIENCE```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1b3a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hv/g5tssjyj43gfwdfvx2cnjt_c0000gn/T/ipykernel_29231/3055432407.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasClassifier(build_fn=create_model, batch_size=100, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 4)                 88        \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8098 - accuracy: 0.2451 - val_loss: 8.6240 - val_accuracy: 0.2527\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.5431 - accuracy: 0.2794 - val_loss: 6.3199 - val_accuracy: 0.2747\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.1639 - accuracy: 0.2917 - val_loss: 4.3361 - val_accuracy: 0.2527\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0855 - accuracy: 0.2917 - val_loss: 2.7080 - val_accuracy: 0.2527\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5016 - accuracy: 0.3627 - val_loss: 1.4979 - val_accuracy: 0.3626\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2548 - accuracy: 0.4044 - val_loss: 0.8097 - val_accuracy: 0.5275\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7747 - accuracy: 0.5833 - val_loss: 0.7358 - val_accuracy: 0.5275\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.5833 - val_loss: 0.6994 - val_accuracy: 0.5275\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.5833 - val_loss: 0.6742 - val_accuracy: 0.5385\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.5833 - val_loss: 0.6554 - val_accuracy: 0.5495\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.5833 - val_loss: 0.6400 - val_accuracy: 0.5385\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6054 - val_loss: 0.6272 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6078 - val_loss: 0.6165 - val_accuracy: 0.5495\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.5539 - val_loss: 0.6072 - val_accuracy: 0.5604\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.5441 - val_loss: 0.5984 - val_accuracy: 0.5824\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.6471 - val_loss: 0.5903 - val_accuracy: 0.8022\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7279 - val_loss: 0.5835 - val_accuracy: 0.7143\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6961 - val_loss: 0.5777 - val_accuracy: 0.7033\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.6961 - val_loss: 0.5726 - val_accuracy: 0.7033\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.6961 - val_loss: 0.5677 - val_accuracy: 0.7033\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.6961 - val_loss: 0.5633 - val_accuracy: 0.7033\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.6961 - val_loss: 0.5595 - val_accuracy: 0.7033\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.6961 - val_loss: 0.5560 - val_accuracy: 0.7802\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7770 - val_loss: 0.5538 - val_accuracy: 0.7802\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7770 - val_loss: 0.5527 - val_accuracy: 0.7802\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7770 - val_loss: 0.5518 - val_accuracy: 0.7802\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7770 - val_loss: 0.5519 - val_accuracy: 0.7802\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7770 - val_loss: 0.5499 - val_accuracy: 0.7802\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7770 - val_loss: 0.5486 - val_accuracy: 0.7802\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7770 - val_loss: 0.5473 - val_accuracy: 0.7802\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7770 - val_loss: 0.5460 - val_accuracy: 0.7802\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7770 - val_loss: 0.5450 - val_accuracy: 0.7802\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7770 - val_loss: 0.5440 - val_accuracy: 0.7802\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7770 - val_loss: 0.5430 - val_accuracy: 0.7802\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7770 - val_loss: 0.5419 - val_accuracy: 0.7802\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7770 - val_loss: 0.5408 - val_accuracy: 0.7802\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7770 - val_loss: 0.5397 - val_accuracy: 0.7802\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7770 - val_loss: 0.5387 - val_accuracy: 0.7802\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7770 - val_loss: 0.5376 - val_accuracy: 0.7802\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7770 - val_loss: 0.5366 - val_accuracy: 0.7802\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7770 - val_loss: 0.5356 - val_accuracy: 0.7802\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7770 - val_loss: 0.5345 - val_accuracy: 0.7802\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7770 - val_loss: 0.5334 - val_accuracy: 0.7802\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7770 - val_loss: 0.5325 - val_accuracy: 0.7802\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7770 - val_loss: 0.5316 - val_accuracy: 0.7802\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7770 - val_loss: 0.5306 - val_accuracy: 0.7802\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7770 - val_loss: 0.5297 - val_accuracy: 0.7802\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7770 - val_loss: 0.5290 - val_accuracy: 0.7802\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7770 - val_loss: 0.5281 - val_accuracy: 0.7802\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7770 - val_loss: 0.5272 - val_accuracy: 0.7802\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7770 - val_loss: 0.5263 - val_accuracy: 0.7802\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7770 - val_loss: 0.5257 - val_accuracy: 0.7802\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7770 - val_loss: 0.5244 - val_accuracy: 0.7802\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7770 - val_loss: 0.5236 - val_accuracy: 0.7802\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7770 - val_loss: 0.5230 - val_accuracy: 0.7802\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7770 - val_loss: 0.5221 - val_accuracy: 0.7802\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7770 - val_loss: 0.5215 - val_accuracy: 0.7802\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5096 - accuracy: 0.7770 - val_loss: 0.5210 - val_accuracy: 0.7802\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7770 - val_loss: 0.5204 - val_accuracy: 0.7802\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7770 - val_loss: 0.5196 - val_accuracy: 0.7802\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7770 - val_loss: 0.5189 - val_accuracy: 0.7802\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7770 - val_loss: 0.5182 - val_accuracy: 0.7802\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7770 - val_loss: 0.5175 - val_accuracy: 0.7802\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7770 - val_loss: 0.5171 - val_accuracy: 0.7802\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7770 - val_loss: 0.5162 - val_accuracy: 0.7802\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7770 - val_loss: 0.5157 - val_accuracy: 0.7802\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7770 - val_loss: 0.5149 - val_accuracy: 0.7802\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7770 - val_loss: 0.5143 - val_accuracy: 0.7802\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7770 - val_loss: 0.5138 - val_accuracy: 0.7802\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7770 - val_loss: 0.5129 - val_accuracy: 0.7802\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7770 - val_loss: 0.5126 - val_accuracy: 0.7802\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7770 - val_loss: 0.5123 - val_accuracy: 0.7802\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7770 - val_loss: 0.5117 - val_accuracy: 0.7802\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7770 - val_loss: 0.5113 - val_accuracy: 0.7802\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7770 - val_loss: 0.5109 - val_accuracy: 0.7802\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7770 - val_loss: 0.5103 - val_accuracy: 0.7802\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7770 - val_loss: 0.5102 - val_accuracy: 0.7802\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7770 - val_loss: 0.5095 - val_accuracy: 0.7802\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7770 - val_loss: 0.5089 - val_accuracy: 0.7802\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7770 - val_loss: 0.5085 - val_accuracy: 0.7802\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7770 - val_loss: 0.5081 - val_accuracy: 0.7802\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7770 - val_loss: 0.5078 - val_accuracy: 0.7802\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7770 - val_loss: 0.5073 - val_accuracy: 0.7802\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7770 - val_loss: 0.5067 - val_accuracy: 0.7802\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7770 - val_loss: 0.5063 - val_accuracy: 0.7802\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7770 - val_loss: 0.5057 - val_accuracy: 0.7802\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7770 - val_loss: 0.5053 - val_accuracy: 0.7802\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7770 - val_loss: 0.5051 - val_accuracy: 0.7802\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7770 - val_loss: 0.5045 - val_accuracy: 0.7802\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7770 - val_loss: 0.5041 - val_accuracy: 0.7802\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7770 - val_loss: 0.5033 - val_accuracy: 0.7802\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7770 - val_loss: 0.5031 - val_accuracy: 0.7802\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7770 - val_loss: 0.5025 - val_accuracy: 0.7802\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7770 - val_loss: 0.5021 - val_accuracy: 0.7802\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7770 - val_loss: 0.5017 - val_accuracy: 0.7802\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7770 - val_loss: 0.5011 - val_accuracy: 0.7802\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7770 - val_loss: 0.5006 - val_accuracy: 0.7802\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7770 - val_loss: 0.5002 - val_accuracy: 0.7802\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7770 - val_loss: 0.4999 - val_accuracy: 0.7802\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7770 - val_loss: 0.4995 - val_accuracy: 0.7802\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.4817 - accuracy: 0.7946\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 4)                 88        \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57.7447 - accuracy: 0.4841 - val_loss: 47.0513 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 49.4808 - accuracy: 0.4817 - val_loss: 40.8973 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 42.3744 - accuracy: 0.4817 - val_loss: 35.4344 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 36.2031 - accuracy: 0.4817 - val_loss: 30.3655 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 30.4914 - accuracy: 0.4817 - val_loss: 25.9210 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 25.6675 - accuracy: 0.4817 - val_loss: 22.0029 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 21.3816 - accuracy: 0.4817 - val_loss: 18.5982 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 17.6476 - accuracy: 0.4817 - val_loss: 15.4738 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 14.2483 - accuracy: 0.4817 - val_loss: 12.5692 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 11.0512 - accuracy: 0.4817 - val_loss: 10.0675 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.2869 - accuracy: 0.4817 - val_loss: 7.9765 - val_accuracy: 0.6374\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.6504 - accuracy: 0.7311 - val_loss: 7.1811 - val_accuracy: 0.7802\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.1994 - accuracy: 0.7946 - val_loss: 6.4135 - val_accuracy: 0.7802\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.6143 - accuracy: 0.7946 - val_loss: 5.8054 - val_accuracy: 0.7802\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.0107 - accuracy: 0.7946 - val_loss: 5.1432 - val_accuracy: 0.7802\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.3247 - accuracy: 0.7946 - val_loss: 4.5508 - val_accuracy: 0.7802\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8491 - accuracy: 0.5966 - val_loss: 4.3511 - val_accuracy: 0.5604\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7171 - accuracy: 0.4817 - val_loss: 3.8052 - val_accuracy: 0.5604\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.1010 - accuracy: 0.5477 - val_loss: 3.1548 - val_accuracy: 0.7802\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.6654 - accuracy: 0.7946 - val_loss: 2.7236 - val_accuracy: 0.7802\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3004 - accuracy: 0.7946 - val_loss: 2.2843 - val_accuracy: 0.7802\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8989 - accuracy: 0.7946 - val_loss: 1.8395 - val_accuracy: 0.7802\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5591 - accuracy: 0.6064 - val_loss: 1.5195 - val_accuracy: 0.6374\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2523 - accuracy: 0.5623 - val_loss: 0.9992 - val_accuracy: 0.7802\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8349 - accuracy: 0.7946 - val_loss: 0.5675 - val_accuracy: 0.7802\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7848 - val_loss: 0.6435 - val_accuracy: 0.5824\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7017 - val_loss: 0.5660 - val_accuracy: 0.5824\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7579 - val_loss: 0.5812 - val_accuracy: 0.7473\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7262 - val_loss: 0.5907 - val_accuracy: 0.7802\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7946 - val_loss: 0.5377 - val_accuracy: 0.7802\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7946 - val_loss: 0.5124 - val_accuracy: 0.7802\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7946 - val_loss: 0.5310 - val_accuracy: 0.7802\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7946 - val_loss: 0.5243 - val_accuracy: 0.7802\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7090 - val_loss: 0.5360 - val_accuracy: 0.7802\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7946 - val_loss: 0.5181 - val_accuracy: 0.7802\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7946 - val_loss: 0.5271 - val_accuracy: 0.7802\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7506 - val_loss: 0.5869 - val_accuracy: 0.5824\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.5941 - val_loss: 0.5308 - val_accuracy: 0.7363\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7922 - val_loss: 0.5262 - val_accuracy: 0.7802\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7946 - val_loss: 0.5237 - val_accuracy: 0.7802\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7946 - val_loss: 0.5057 - val_accuracy: 0.7802\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7946 - val_loss: 0.5364 - val_accuracy: 0.7802\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7946 - val_loss: 0.5230 - val_accuracy: 0.7802\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7946 - val_loss: 0.5139 - val_accuracy: 0.7802\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7946 - val_loss: 0.5358 - val_accuracy: 0.7802\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7946 - val_loss: 0.5103 - val_accuracy: 0.7802\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7946 - val_loss: 0.5481 - val_accuracy: 0.6264\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.6846 - val_loss: 0.5421 - val_accuracy: 0.7582\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7897 - val_loss: 0.5193 - val_accuracy: 0.7802\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7946 - val_loss: 0.5060 - val_accuracy: 0.7802\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7946 - val_loss: 0.5099 - val_accuracy: 0.7802\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7946 - val_loss: 0.5373 - val_accuracy: 0.7802\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.6357 - val_loss: 0.5645 - val_accuracy: 0.7473\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7506 - val_loss: 0.5152 - val_accuracy: 0.7802\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7946 - val_loss: 0.5134 - val_accuracy: 0.7802\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7946 - val_loss: 0.5053 - val_accuracy: 0.7802\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7946 - val_loss: 0.5148 - val_accuracy: 0.7802\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7946 - val_loss: 0.5027 - val_accuracy: 0.7802\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7946 - val_loss: 0.4998 - val_accuracy: 0.7802\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7946 - val_loss: 0.4990 - val_accuracy: 0.7802\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7946 - val_loss: 0.5103 - val_accuracy: 0.7802\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7946 - val_loss: 0.5159 - val_accuracy: 0.7582\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7775 - val_loss: 0.5144 - val_accuracy: 0.7802\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7946 - val_loss: 0.5049 - val_accuracy: 0.7802\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7506 - val_loss: 0.5624 - val_accuracy: 0.7473\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7579 - val_loss: 0.4982 - val_accuracy: 0.7802\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7946 - val_loss: 0.5115 - val_accuracy: 0.7802\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7946 - val_loss: 0.4966 - val_accuracy: 0.7802\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7946 - val_loss: 0.5236 - val_accuracy: 0.7582\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7873 - val_loss: 0.4961 - val_accuracy: 0.7802\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7946 - val_loss: 0.4935 - val_accuracy: 0.7802\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7946 - val_loss: 0.5131 - val_accuracy: 0.7802\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7946 - val_loss: 0.5396 - val_accuracy: 0.6154\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.6822 - val_loss: 0.5109 - val_accuracy: 0.7802\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7946 - val_loss: 0.5011 - val_accuracy: 0.7802\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7897 - val_loss: 0.4987 - val_accuracy: 0.7802\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7946 - val_loss: 0.5025 - val_accuracy: 0.7802\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7995 - val_loss: 0.5633 - val_accuracy: 0.7802\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7922 - val_loss: 0.4916 - val_accuracy: 0.7802\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7946 - val_loss: 0.4969 - val_accuracy: 0.7802\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7946 - val_loss: 0.5126 - val_accuracy: 0.7802\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7359 - val_loss: 0.5264 - val_accuracy: 0.7802\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7946 - val_loss: 0.5059 - val_accuracy: 0.7802\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.6822 - val_loss: 0.6190 - val_accuracy: 0.6374\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.6553 - val_loss: 0.5288 - val_accuracy: 0.8681\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7262 - val_loss: 0.5365 - val_accuracy: 0.7802\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5515 - accuracy: 0.7946 - val_loss: 0.4966 - val_accuracy: 0.7802\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7946 - val_loss: 0.5081 - val_accuracy: 0.7582\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7971 - val_loss: 0.5054 - val_accuracy: 0.7802\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7946 - val_loss: 0.4923 - val_accuracy: 0.7802\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7946 - val_loss: 0.4946 - val_accuracy: 0.7802\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7946 - val_loss: 0.5572 - val_accuracy: 0.7692\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6748 - val_loss: 0.5500 - val_accuracy: 0.6044\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7897 - val_loss: 0.5038 - val_accuracy: 0.7802\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7946 - val_loss: 0.5283 - val_accuracy: 0.7802\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7604 - val_loss: 0.5777 - val_accuracy: 0.7473\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7802\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7946 - val_loss: 0.5317 - val_accuracy: 0.7802\n",
      "Epoch 99/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6993 - accuracy: 0.7600Restoring model weights from the end of the best epoch: 79.\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7946 - val_loss: 0.4931 - val_accuracy: 0.7802\n",
      "Epoch 00099: early stopping\n",
      "5/5 [==============================] - 0s 697us/step - loss: 0.4821 - accuracy: 0.7770\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 8)                 176       \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 63.7350 - accuracy: 0.3284 - val_loss: 48.5589 - val_accuracy: 0.4396\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 43.5161 - accuracy: 0.4583 - val_loss: 34.8649 - val_accuracy: 0.4286\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 29.9420 - accuracy: 0.5049 - val_loss: 29.6428 - val_accuracy: 0.7802\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 26.5267 - accuracy: 0.7770 - val_loss: 20.9956 - val_accuracy: 0.7802\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 16.0734 - accuracy: 0.7672 - val_loss: 8.3089 - val_accuracy: 0.5275\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.4698 - accuracy: 0.4877 - val_loss: 7.3325 - val_accuracy: 0.4176\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.9044 - accuracy: 0.5245 - val_loss: 6.6199 - val_accuracy: 0.7802\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.7214 - accuracy: 0.7745 - val_loss: 3.6210 - val_accuracy: 0.7033\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2431 - accuracy: 0.5539 - val_loss: 3.1263 - val_accuracy: 0.7143\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.5182 - accuracy: 0.6936 - val_loss: 2.4594 - val_accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1028 - accuracy: 0.5760 - val_loss: 1.7445 - val_accuracy: 0.5824\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7559 - accuracy: 0.7108 - val_loss: 1.3281 - val_accuracy: 0.8022\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.4353 - accuracy: 0.5123 - val_loss: 3.4627 - val_accuracy: 0.7802\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.3059 - accuracy: 0.7770 - val_loss: 2.5558 - val_accuracy: 0.7692\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2268 - accuracy: 0.6127 - val_loss: 1.6756 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7901 - accuracy: 0.7892 - val_loss: 4.5040 - val_accuracy: 0.7802\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4984 - accuracy: 0.7304 - val_loss: 1.3668 - val_accuracy: 0.8571\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8986 - accuracy: 0.8333 - val_loss: 5.5928 - val_accuracy: 0.7802\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6961 - accuracy: 0.8211 - val_loss: 1.6570 - val_accuracy: 0.8462\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8141 - accuracy: 0.5049 - val_loss: 1.2411 - val_accuracy: 0.8681\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6046 - accuracy: 0.8554 - val_loss: 0.5824 - val_accuracy: 0.8681\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.7794 - val_loss: 0.3224 - val_accuracy: 0.8681\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7966 - val_loss: 0.6305 - val_accuracy: 0.8242\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.8162 - val_loss: 0.6163 - val_accuracy: 0.8681\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.8186 - val_loss: 1.7033 - val_accuracy: 0.8681\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3536 - accuracy: 0.8480 - val_loss: 1.4815 - val_accuracy: 0.6923\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9290 - accuracy: 0.7623 - val_loss: 1.1849 - val_accuracy: 0.8681\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8212 - accuracy: 0.8529 - val_loss: 1.8720 - val_accuracy: 0.6923\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1682 - accuracy: 0.7794 - val_loss: 0.8244 - val_accuracy: 0.8681\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0346 - accuracy: 0.7672 - val_loss: 1.7899 - val_accuracy: 0.8681\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8387 - accuracy: 0.8529 - val_loss: 1.0219 - val_accuracy: 0.8681\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6580 - accuracy: 0.7525 - val_loss: 1.8278 - val_accuracy: 0.8681\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5778 - accuracy: 0.8505 - val_loss: 2.3654 - val_accuracy: 0.8681\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6609 - accuracy: 0.8162 - val_loss: 0.4020 - val_accuracy: 0.8462\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0050 - accuracy: 0.8897 - val_loss: 0.8909 - val_accuracy: 0.8901\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7453 - accuracy: 0.8873 - val_loss: 0.4617 - val_accuracy: 0.8791\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.9069 - val_loss: 0.7200 - val_accuracy: 0.8901\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.9118 - val_loss: 1.0346 - val_accuracy: 0.8901\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.9216 - val_loss: 0.8336 - val_accuracy: 0.8901\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3220 - accuracy: 0.9069 - val_loss: 1.1714 - val_accuracy: 0.8901\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.8946 - val_loss: 0.4187 - val_accuracy: 0.8901\n",
      "Epoch 42/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2551 - accuracy: 0.9400Restoring model weights from the end of the best epoch: 22.\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.9240 - val_loss: 1.3202 - val_accuracy: 0.6923\n",
      "Epoch 00042: early stopping\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.3718 - accuracy: 0.8484\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_155 (Dense)           (None, 8)                 176       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 69.3582 - accuracy: 0.5183 - val_loss: 46.6421 - val_accuracy: 0.4176\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 48.5453 - accuracy: 0.5183 - val_loss: 32.5823 - val_accuracy: 0.4176\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 32.2636 - accuracy: 0.3814 - val_loss: 28.1275 - val_accuracy: 0.2088\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 26.1053 - accuracy: 0.2910 - val_loss: 22.5424 - val_accuracy: 0.2967\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 24.9121 - accuracy: 0.4279 - val_loss: 20.5179 - val_accuracy: 0.5604\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 21.6602 - accuracy: 0.5599 - val_loss: 17.3854 - val_accuracy: 0.4176\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 19.5992 - accuracy: 0.3081 - val_loss: 15.7130 - val_accuracy: 0.3846\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 16.4468 - accuracy: 0.5110 - val_loss: 15.0245 - val_accuracy: 0.5824\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 15.9451 - accuracy: 0.5966 - val_loss: 12.8158 - val_accuracy: 0.5055\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 13.5318 - accuracy: 0.4034 - val_loss: 11.1489 - val_accuracy: 0.4286\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 11.2326 - accuracy: 0.5379 - val_loss: 10.0159 - val_accuracy: 0.5495\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.9833 - accuracy: 0.5306 - val_loss: 8.5130 - val_accuracy: 0.4615\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.9070 - accuracy: 0.5966 - val_loss: 6.4388 - val_accuracy: 0.5604\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.7171 - accuracy: 0.6504 - val_loss: 4.4669 - val_accuracy: 0.6154\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7634 - accuracy: 0.6822 - val_loss: 3.4813 - val_accuracy: 0.6154\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0482 - accuracy: 0.6748 - val_loss: 2.8496 - val_accuracy: 0.6154\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3490 - accuracy: 0.6919 - val_loss: 2.3271 - val_accuracy: 0.6374\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7634 - accuracy: 0.6895 - val_loss: 1.3610 - val_accuracy: 0.6374\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7473 - accuracy: 0.8362 - val_loss: 1.0268 - val_accuracy: 0.8132\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7652 - accuracy: 0.8484 - val_loss: 0.8522 - val_accuracy: 0.7802\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.8704 - val_loss: 0.8121 - val_accuracy: 0.8132\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8826 - val_loss: 0.7892 - val_accuracy: 0.7912\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8753 - val_loss: 0.9360 - val_accuracy: 0.8022\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7938 - accuracy: 0.8557 - val_loss: 1.0612 - val_accuracy: 0.8132\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7268 - accuracy: 0.8704 - val_loss: 0.8078 - val_accuracy: 0.8022\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.8729 - val_loss: 0.8058 - val_accuracy: 0.8132\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.8557 - val_loss: 0.7869 - val_accuracy: 0.7802\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.8704 - val_loss: 0.8953 - val_accuracy: 0.8242\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2478 - accuracy: 0.7751 - val_loss: 1.3723 - val_accuracy: 0.8242\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5336 - accuracy: 0.8753 - val_loss: 0.7914 - val_accuracy: 0.7802\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3615 - accuracy: 0.7506 - val_loss: 1.1070 - val_accuracy: 0.8242\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4209 - accuracy: 0.8778 - val_loss: 0.8413 - val_accuracy: 0.8022\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7872 - accuracy: 0.8460 - val_loss: 0.8364 - val_accuracy: 0.8022\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.8802 - val_loss: 0.8426 - val_accuracy: 0.8022\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.8704 - val_loss: 0.9891 - val_accuracy: 0.8242\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.8826 - val_loss: 1.0635 - val_accuracy: 0.8132\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.8484 - val_loss: 1.1049 - val_accuracy: 0.8242\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.8704 - val_loss: 0.8479 - val_accuracy: 0.8132\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.8704 - val_loss: 0.8366 - val_accuracy: 0.8242\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7623 - accuracy: 0.8533 - val_loss: 0.8227 - val_accuracy: 0.8242\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.8753 - val_loss: 0.8609 - val_accuracy: 0.8242\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.8778 - val_loss: 0.8348 - val_accuracy: 0.8242\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.8753 - val_loss: 1.2576 - val_accuracy: 0.7802\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9563 - accuracy: 0.8362 - val_loss: 1.1056 - val_accuracy: 0.8242\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7462 - accuracy: 0.8802 - val_loss: 0.7543 - val_accuracy: 0.7912\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8729 - val_loss: 1.0125 - val_accuracy: 0.8242\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7311 - accuracy: 0.8606 - val_loss: 0.7863 - val_accuracy: 0.8132\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.8606 - val_loss: 1.9142 - val_accuracy: 0.6813\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.0610 - accuracy: 0.5746 - val_loss: 1.0126 - val_accuracy: 0.8132\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4839 - accuracy: 0.8435 - val_loss: 3.9017 - val_accuracy: 0.8352\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2035 - accuracy: 0.8753 - val_loss: 2.9474 - val_accuracy: 0.8242\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3643 - accuracy: 0.8778 - val_loss: 2.6681 - val_accuracy: 0.6813\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.0448 - accuracy: 0.6748 - val_loss: 1.1476 - val_accuracy: 0.8242\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4210 - accuracy: 0.8778 - val_loss: 1.1147 - val_accuracy: 0.8352\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1980 - accuracy: 0.8337 - val_loss: 1.2353 - val_accuracy: 0.8132\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.8606 - val_loss: 1.0983 - val_accuracy: 0.8352\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.8924 - val_loss: 1.3434 - val_accuracy: 0.8352\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9682 - accuracy: 0.8484 - val_loss: 1.1679 - val_accuracy: 0.8352\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.8826 - val_loss: 1.0565 - val_accuracy: 0.8352\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.8802 - val_loss: 1.0754 - val_accuracy: 0.8352\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.8949 - val_loss: 0.9339 - val_accuracy: 0.8022\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.8655 - val_loss: 1.0105 - val_accuracy: 0.8352\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.8729 - val_loss: 1.0045 - val_accuracy: 0.8352\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.8484 - val_loss: 1.1592 - val_accuracy: 0.8352\n",
      "Epoch 65/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3174 - accuracy: 0.8000Restoring model weights from the end of the best epoch: 45.\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8827 - accuracy: 0.8729 - val_loss: 0.8712 - val_accuracy: 0.8022\n",
      "Epoch 00065: early stopping\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.7672 - accuracy: 0.8627\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,185\n",
      "Trainable params: 1,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 98.2564 - accuracy: 0.7770 - val_loss: 86.3663 - val_accuracy: 0.7802\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 69.3035 - accuracy: 0.7770 - val_loss: 55.0187 - val_accuracy: 0.7802\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 42.3559 - accuracy: 0.7819 - val_loss: 29.2200 - val_accuracy: 0.7802\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 22.0065 - accuracy: 0.7525 - val_loss: 17.0346 - val_accuracy: 0.7033\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 14.1807 - accuracy: 0.7279 - val_loss: 12.4031 - val_accuracy: 0.7802\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 10.3968 - accuracy: 0.7794 - val_loss: 7.7500 - val_accuracy: 0.7692\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0222 - accuracy: 0.7402 - val_loss: 4.9602 - val_accuracy: 0.6813\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0489 - accuracy: 0.7083 - val_loss: 3.6039 - val_accuracy: 0.7582\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.2448 - accuracy: 0.8431 - val_loss: 4.1007 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5912 - accuracy: 0.8725 - val_loss: 3.5499 - val_accuracy: 0.8242\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9788 - accuracy: 0.8431 - val_loss: 2.9839 - val_accuracy: 0.7802\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7019 - accuracy: 0.8505 - val_loss: 3.0847 - val_accuracy: 0.8022\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7191 - accuracy: 0.8529 - val_loss: 3.4807 - val_accuracy: 0.7363\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1593 - accuracy: 0.8064 - val_loss: 4.0498 - val_accuracy: 0.8242\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6368 - accuracy: 0.8676 - val_loss: 3.1392 - val_accuracy: 0.8571\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.6465 - accuracy: 0.8676 - val_loss: 2.6652 - val_accuracy: 0.8352\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.5968 - accuracy: 0.8873 - val_loss: 3.3115 - val_accuracy: 0.7692\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1944 - accuracy: 0.8382 - val_loss: 3.0976 - val_accuracy: 0.8352\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5202 - accuracy: 0.8676 - val_loss: 2.8387 - val_accuracy: 0.7802\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4491 - accuracy: 0.8627 - val_loss: 3.7502 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9975 - accuracy: 0.9020 - val_loss: 3.2797 - val_accuracy: 0.7582\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4117 - accuracy: 0.8235 - val_loss: 2.9445 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.6888 - accuracy: 0.8897 - val_loss: 2.6497 - val_accuracy: 0.7802\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6870 - accuracy: 0.8505 - val_loss: 3.1430 - val_accuracy: 0.7582\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8000 - accuracy: 0.8260 - val_loss: 2.6003 - val_accuracy: 0.7802\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6764 - accuracy: 0.8922 - val_loss: 3.8747 - val_accuracy: 0.8571\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8846 - accuracy: 0.9020 - val_loss: 2.4046 - val_accuracy: 0.8132\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3450 - accuracy: 0.8799 - val_loss: 2.5289 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6800 - accuracy: 0.8676 - val_loss: 3.0464 - val_accuracy: 0.7692\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.5729 - accuracy: 0.8284 - val_loss: 3.1361 - val_accuracy: 0.8901\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7067 - accuracy: 0.8897 - val_loss: 4.5015 - val_accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2446 - accuracy: 0.9020 - val_loss: 3.0642 - val_accuracy: 0.7692\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9712 - accuracy: 0.8309 - val_loss: 3.4305 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7473 - accuracy: 0.8848 - val_loss: 4.0213 - val_accuracy: 0.8901\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9732 - accuracy: 0.8750 - val_loss: 2.3943 - val_accuracy: 0.7802\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3905 - accuracy: 0.8922 - val_loss: 2.4051 - val_accuracy: 0.8571\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5984 - accuracy: 0.8505 - val_loss: 2.2281 - val_accuracy: 0.7582\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3481 - accuracy: 0.8603 - val_loss: 2.4656 - val_accuracy: 0.8901\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0625 - accuracy: 0.9191 - val_loss: 2.3617 - val_accuracy: 0.7912\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2980 - accuracy: 0.8750 - val_loss: 2.6740 - val_accuracy: 0.8571\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5447 - accuracy: 0.9020 - val_loss: 2.4704 - val_accuracy: 0.7912\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7686 - accuracy: 0.8407 - val_loss: 2.0397 - val_accuracy: 0.7802\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.1606 - accuracy: 0.7892 - val_loss: 1.9368 - val_accuracy: 0.9011\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7396 - accuracy: 0.8676 - val_loss: 2.6235 - val_accuracy: 0.8571\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4470 - accuracy: 0.8873 - val_loss: 2.4577 - val_accuracy: 0.7582\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3261 - accuracy: 0.8554 - val_loss: 3.5966 - val_accuracy: 0.8571\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5512 - accuracy: 0.9020 - val_loss: 3.4868 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6943 - accuracy: 0.8824 - val_loss: 2.7446 - val_accuracy: 0.7912\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8443 - accuracy: 0.8407 - val_loss: 3.5903 - val_accuracy: 0.9011\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9004 - accuracy: 0.8676 - val_loss: 3.8824 - val_accuracy: 0.8901\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6927 - accuracy: 0.9216 - val_loss: 2.6535 - val_accuracy: 0.7912\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9935 - accuracy: 0.8358 - val_loss: 2.7170 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7803 - accuracy: 0.9020 - val_loss: 2.1469 - val_accuracy: 0.8901\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2308 - accuracy: 0.8775 - val_loss: 2.4574 - val_accuracy: 0.8901\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8173 - accuracy: 0.8750 - val_loss: 5.1676 - val_accuracy: 0.9011\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2434 - accuracy: 0.8971 - val_loss: 1.4197 - val_accuracy: 0.8352\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8727 - accuracy: 0.8015 - val_loss: 1.7214 - val_accuracy: 0.7582\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8544 - accuracy: 0.8897 - val_loss: 3.3705 - val_accuracy: 0.8901\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5861 - accuracy: 0.9142 - val_loss: 1.6132 - val_accuracy: 0.8681\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1916 - accuracy: 0.8995 - val_loss: 2.2626 - val_accuracy: 0.9011\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9153 - accuracy: 0.9069 - val_loss: 1.2870 - val_accuracy: 0.8681\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2944 - accuracy: 0.9240 - val_loss: 1.3856 - val_accuracy: 0.8132\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.6344 - accuracy: 0.7966 - val_loss: 1.8281 - val_accuracy: 0.7912\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6561 - accuracy: 0.9069 - val_loss: 3.7826 - val_accuracy: 0.9011\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3113 - accuracy: 0.9191 - val_loss: 1.8867 - val_accuracy: 0.8901\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4397 - accuracy: 0.9020 - val_loss: 1.8602 - val_accuracy: 0.8571\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3887 - accuracy: 0.9265 - val_loss: 2.8257 - val_accuracy: 0.8901\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2024 - accuracy: 0.9167 - val_loss: 2.0621 - val_accuracy: 0.8132\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4561 - accuracy: 0.8775 - val_loss: 2.4256 - val_accuracy: 0.8901\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3773 - accuracy: 0.9314 - val_loss: 1.4249 - val_accuracy: 0.8681\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9959 - accuracy: 0.9069 - val_loss: 1.2698 - val_accuracy: 0.8681\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.9118 - val_loss: 1.3958 - val_accuracy: 0.8901\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.9093 - val_loss: 0.8917 - val_accuracy: 0.8901\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.8971 - val_loss: 1.0788 - val_accuracy: 0.8901\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.9338 - val_loss: 1.4710 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9794 - accuracy: 0.9020 - val_loss: 1.2813 - val_accuracy: 0.9011\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.9020 - val_loss: 2.1200 - val_accuracy: 0.8901\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9218 - accuracy: 0.9314 - val_loss: 4.6482 - val_accuracy: 0.8901\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8221 - accuracy: 0.9314 - val_loss: 1.0651 - val_accuracy: 0.8901\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3002 - accuracy: 0.8480 - val_loss: 2.3416 - val_accuracy: 0.8901\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7305 - accuracy: 0.9363 - val_loss: 6.1728 - val_accuracy: 0.9011\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6346 - accuracy: 0.9338 - val_loss: 2.6634 - val_accuracy: 0.8901\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7455 - accuracy: 0.7696 - val_loss: 6.8155 - val_accuracy: 0.6813\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8548 - accuracy: 0.8113 - val_loss: 4.9025 - val_accuracy: 0.9011\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.5393 - accuracy: 0.9387 - val_loss: 6.5183 - val_accuracy: 0.9011\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6856 - accuracy: 0.9314 - val_loss: 3.7870 - val_accuracy: 0.8901\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7351 - accuracy: 0.9216 - val_loss: 1.1161 - val_accuracy: 0.8022\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7728 - accuracy: 0.9142 - val_loss: 0.7675 - val_accuracy: 0.8681\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4149 - accuracy: 0.8824 - val_loss: 1.0819 - val_accuracy: 0.9011\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9303 - accuracy: 0.9363 - val_loss: 0.7451 - val_accuracy: 0.8352\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9121 - accuracy: 0.8725 - val_loss: 1.4040 - val_accuracy: 0.8901\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9118 - accuracy: 0.9338 - val_loss: 0.6399 - val_accuracy: 0.8571\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.9191 - val_loss: 0.9125 - val_accuracy: 0.8901\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.9314 - val_loss: 0.9546 - val_accuracy: 0.8352\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.8946 - val_loss: 1.3248 - val_accuracy: 0.9011\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.9363 - val_loss: 1.1070 - val_accuracy: 0.8571\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.9069 - val_loss: 1.4552 - val_accuracy: 0.8901\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9041 - accuracy: 0.9314 - val_loss: 3.6649 - val_accuracy: 0.7582\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.7322 - accuracy: 0.7108 - val_loss: 0.8344 - val_accuracy: 0.8901\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3885 - accuracy: 0.9289 - val_loss: 3.7234 - val_accuracy: 0.8901\n",
      "5/5 [==============================] - 0s 550us/step - loss: 4.5361 - accuracy: 0.9071\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_165 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,185\n",
      "Trainable params: 1,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75.4529 - accuracy: 0.7946 - val_loss: 37.4310 - val_accuracy: 0.7802\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 50.5761 - accuracy: 0.7946 - val_loss: 21.9620 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 29.0851 - accuracy: 0.6553 - val_loss: 9.7791 - val_accuracy: 0.6593\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.9092 - accuracy: 0.7457 - val_loss: 1.8309 - val_accuracy: 0.7912\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5332 - accuracy: 0.7482 - val_loss: 1.5488 - val_accuracy: 0.5934\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.9767 - accuracy: 0.6528 - val_loss: 1.9350 - val_accuracy: 0.6703\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3620 - accuracy: 0.7286 - val_loss: 1.3283 - val_accuracy: 0.6703\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7026 - accuracy: 0.6822 - val_loss: 1.3958 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6180 - accuracy: 0.6748 - val_loss: 1.2190 - val_accuracy: 0.6813\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5732 - accuracy: 0.6748 - val_loss: 1.1868 - val_accuracy: 0.7253\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3180 - accuracy: 0.7017 - val_loss: 1.1142 - val_accuracy: 0.7363\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1663 - accuracy: 0.6944 - val_loss: 1.0276 - val_accuracy: 0.6044\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3275 - accuracy: 0.7555 - val_loss: 0.8950 - val_accuracy: 0.6923\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1937 - accuracy: 0.6993 - val_loss: 0.8881 - val_accuracy: 0.7143\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0885 - accuracy: 0.7506 - val_loss: 0.7210 - val_accuracy: 0.6923\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5323 - accuracy: 0.6822 - val_loss: 1.3743 - val_accuracy: 0.6703\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9307 - accuracy: 0.7555 - val_loss: 1.0054 - val_accuracy: 0.8242\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0082 - accuracy: 0.8362 - val_loss: 0.7501 - val_accuracy: 0.7473\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4204 - accuracy: 0.6846 - val_loss: 0.8021 - val_accuracy: 0.7473\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8584 - accuracy: 0.8826 - val_loss: 1.0445 - val_accuracy: 0.9121\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0921 - accuracy: 0.8949 - val_loss: 0.5220 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7311 - val_loss: 0.4970 - val_accuracy: 0.9121\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4389 - accuracy: 0.9291 - val_loss: 0.5859 - val_accuracy: 0.7473\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8637 - accuracy: 0.7139 - val_loss: 0.6413 - val_accuracy: 0.7473\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8509 - val_loss: 0.5584 - val_accuracy: 0.9121\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8851 - val_loss: 0.6161 - val_accuracy: 0.8242\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8802 - val_loss: 0.6152 - val_accuracy: 0.9121\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.9242 - val_loss: 0.6382 - val_accuracy: 0.8242\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9676 - accuracy: 0.7066 - val_loss: 0.4818 - val_accuracy: 0.9011\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7720 - accuracy: 0.8802 - val_loss: 0.9517 - val_accuracy: 0.9121\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9484 - accuracy: 0.9218 - val_loss: 0.4422 - val_accuracy: 0.9121\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8631 - val_loss: 0.4276 - val_accuracy: 0.8901\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.9364 - val_loss: 0.6023 - val_accuracy: 0.9121\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.9193 - val_loss: 0.6295 - val_accuracy: 0.8242\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.8166 - val_loss: 0.4579 - val_accuracy: 0.9121\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.9267 - val_loss: 0.4094 - val_accuracy: 0.9121\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.9267 - val_loss: 0.4364 - val_accuracy: 0.9011\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.9218 - val_loss: 0.4187 - val_accuracy: 0.9121\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.9340 - val_loss: 0.4373 - val_accuracy: 0.9011\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.9315 - val_loss: 0.4075 - val_accuracy: 0.9121\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.9364 - val_loss: 0.3843 - val_accuracy: 0.8901\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.9169 - val_loss: 0.3857 - val_accuracy: 0.9121\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.9242 - val_loss: 0.4271 - val_accuracy: 0.9121\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.9291 - val_loss: 0.4005 - val_accuracy: 0.9231\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8289 - val_loss: 0.3905 - val_accuracy: 0.9011\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.9340 - val_loss: 0.4032 - val_accuracy: 0.9121\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.9193 - val_loss: 0.4022 - val_accuracy: 0.9231\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.9364 - val_loss: 0.3836 - val_accuracy: 0.9121\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.9291 - val_loss: 0.3501 - val_accuracy: 0.8901\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.9267 - val_loss: 0.3670 - val_accuracy: 0.9011\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.9364 - val_loss: 0.4131 - val_accuracy: 0.9121\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.9291 - val_loss: 0.4563 - val_accuracy: 0.9121\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2900 - accuracy: 0.9364 - val_loss: 0.3886 - val_accuracy: 0.9231\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.9218 - val_loss: 0.3533 - val_accuracy: 0.9121\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9291 - val_loss: 0.3385 - val_accuracy: 0.8901\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.9242 - val_loss: 0.3205 - val_accuracy: 0.8901\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9267 - val_loss: 0.3369 - val_accuracy: 0.9121\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.9120 - val_loss: 0.3811 - val_accuracy: 0.9011\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.9193 - val_loss: 0.3103 - val_accuracy: 0.8901\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.9242 - val_loss: 0.3009 - val_accuracy: 0.8901\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.9242 - val_loss: 0.3066 - val_accuracy: 0.8901\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9242 - val_loss: 0.4127 - val_accuracy: 0.9121\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.9291 - val_loss: 0.3588 - val_accuracy: 0.9121\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.9291 - val_loss: 0.3167 - val_accuracy: 0.9011\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.9389 - val_loss: 0.3059 - val_accuracy: 0.9121\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3098 - accuracy: 0.9267 - val_loss: 0.4315 - val_accuracy: 0.9121\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.9267 - val_loss: 0.4762 - val_accuracy: 0.9121\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.9267 - val_loss: 0.4183 - val_accuracy: 0.9121\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.9364 - val_loss: 0.4602 - val_accuracy: 0.9121\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.9267 - val_loss: 0.2854 - val_accuracy: 0.8901\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9267 - val_loss: 0.2954 - val_accuracy: 0.8901\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.9291 - val_loss: 0.3033 - val_accuracy: 0.9121\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9291 - val_loss: 0.2891 - val_accuracy: 0.9121\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9242 - val_loss: 0.2777 - val_accuracy: 0.8901\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9315 - val_loss: 0.2835 - val_accuracy: 0.9121\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9242 - val_loss: 0.3265 - val_accuracy: 0.9121\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.9267 - val_loss: 0.2712 - val_accuracy: 0.9121\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9291 - val_loss: 0.3040 - val_accuracy: 0.9121\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9267 - val_loss: 0.3210 - val_accuracy: 0.9011\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.9267 - val_loss: 0.2543 - val_accuracy: 0.8901\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2739 - accuracy: 0.9169 - val_loss: 0.2685 - val_accuracy: 0.9121\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.9315 - val_loss: 0.2591 - val_accuracy: 0.8901\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2372 - accuracy: 0.8998 - val_loss: 0.3209 - val_accuracy: 0.8022\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.9071 - val_loss: 0.3143 - val_accuracy: 0.9121\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.9242 - val_loss: 0.3006 - val_accuracy: 0.8901\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2280 - accuracy: 0.9315 - val_loss: 0.2534 - val_accuracy: 0.9121\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9340 - val_loss: 0.2579 - val_accuracy: 0.8901\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9291 - val_loss: 0.2508 - val_accuracy: 0.8901\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.9267 - val_loss: 0.3059 - val_accuracy: 0.9121\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.9218 - val_loss: 0.2657 - val_accuracy: 0.8901\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9291 - val_loss: 0.2490 - val_accuracy: 0.9121\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9291 - val_loss: 0.2533 - val_accuracy: 0.9121\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2130 - accuracy: 0.9315 - val_loss: 0.2539 - val_accuracy: 0.8901\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9340 - val_loss: 0.2507 - val_accuracy: 0.8901\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9242 - val_loss: 0.3562 - val_accuracy: 0.9231\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8655 - val_loss: 0.3179 - val_accuracy: 0.9121\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.9291 - val_loss: 0.4462 - val_accuracy: 0.9231\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.4210 - accuracy: 0.7384 - val_loss: 0.6844 - val_accuracy: 0.7692\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.8362 - val_loss: 0.8147 - val_accuracy: 0.9121\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0381 - accuracy: 0.9291 - val_loss: 0.5936 - val_accuracy: 0.9121\n",
      "5/5 [==============================] - 0s 591us/step - loss: 0.5155 - accuracy: 0.8873\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 16)                352       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,185\n",
      "Trainable params: 1,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 4.6372 - accuracy: 0.6610 - val_loss: 1.8862 - val_accuracy: 0.7692\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.6296 - accuracy: 0.8605 - val_loss: 1.0157 - val_accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8071 - accuracy: 0.8360 - val_loss: 1.1861 - val_accuracy: 0.8571\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7918 - accuracy: 0.8752 - val_loss: 1.1313 - val_accuracy: 0.8571\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8693 - accuracy: 0.8556 - val_loss: 1.0549 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.8849 - val_loss: 0.9200 - val_accuracy: 0.8901\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.8886 - val_loss: 1.2040 - val_accuracy: 0.8901\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7895 - accuracy: 0.8935 - val_loss: 0.6081 - val_accuracy: 0.9011\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.9168 - val_loss: 0.7408 - val_accuracy: 0.9121\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.2216 - accuracy: 0.9339 - val_loss: 0.4811 - val_accuracy: 0.8901\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7726 - accuracy: 0.8800 - val_loss: 0.5317 - val_accuracy: 0.9121\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.9278 - val_loss: 0.6411 - val_accuracy: 0.9121\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.9290 - val_loss: 0.3479 - val_accuracy: 0.8901\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.9278 - val_loss: 0.3686 - val_accuracy: 0.9011\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.9155 - val_loss: 0.3556 - val_accuracy: 0.9121\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.9351 - val_loss: 0.4769 - val_accuracy: 0.9121\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.9168 - val_loss: 0.2911 - val_accuracy: 0.9011\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.9131 - val_loss: 0.5019 - val_accuracy: 0.9121\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.9058 - val_loss: 0.2538 - val_accuracy: 0.9121\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9168 - val_loss: 0.3773 - val_accuracy: 0.9231\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.9229 - val_loss: 0.2210 - val_accuracy: 0.9011\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9253 - val_loss: 0.3999 - val_accuracy: 0.8901\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.9070 - val_loss: 0.3097 - val_accuracy: 0.9231\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9327 - val_loss: 0.2062 - val_accuracy: 0.8901\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9364 - val_loss: 0.1986 - val_accuracy: 0.8901\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9278 - val_loss: 0.3887 - val_accuracy: 0.9121\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.9070 - val_loss: 0.2682 - val_accuracy: 0.9011\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.9204 - val_loss: 0.2610 - val_accuracy: 0.9451\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.9302 - val_loss: 0.2588 - val_accuracy: 0.9121\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9315 - val_loss: 0.2719 - val_accuracy: 0.9121\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9253 - val_loss: 0.2900 - val_accuracy: 0.9121\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9339 - val_loss: 0.2387 - val_accuracy: 0.9451\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2628 - accuracy: 0.9351 - val_loss: 0.4939 - val_accuracy: 0.8791\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.9119 - val_loss: 0.2344 - val_accuracy: 0.9121\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9290 - val_loss: 0.2768 - val_accuracy: 0.9121\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.9217 - val_loss: 0.4062 - val_accuracy: 0.9121\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.9192 - val_loss: 0.5134 - val_accuracy: 0.8681\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.9106 - val_loss: 0.2022 - val_accuracy: 0.8901\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.9180 - val_loss: 0.2868 - val_accuracy: 0.9231\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9315 - val_loss: 0.2463 - val_accuracy: 0.9121\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9351 - val_loss: 0.3123 - val_accuracy: 0.9121\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9192 - val_loss: 0.2928 - val_accuracy: 0.9121\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.9033 - val_loss: 0.2301 - val_accuracy: 0.9121\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.9119 - val_loss: 0.3956 - val_accuracy: 0.9121\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.9290 - val_loss: 0.1793 - val_accuracy: 0.9121\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9364 - val_loss: 0.1875 - val_accuracy: 0.9121\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.9217 - val_loss: 0.1901 - val_accuracy: 0.9231\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.9082 - val_loss: 0.1776 - val_accuracy: 0.9011\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.9315 - val_loss: 0.2912 - val_accuracy: 0.9121\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9315 - val_loss: 0.2770 - val_accuracy: 0.9231\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9217 - val_loss: 0.1726 - val_accuracy: 0.9121\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9302 - val_loss: 0.1707 - val_accuracy: 0.9341\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9327 - val_loss: 0.1675 - val_accuracy: 0.9341\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9241 - val_loss: 0.3830 - val_accuracy: 0.8901\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.9119 - val_loss: 0.1643 - val_accuracy: 0.9341\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.9143 - val_loss: 0.3827 - val_accuracy: 0.9121\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.9241 - val_loss: 0.1644 - val_accuracy: 0.9121\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9266 - val_loss: 0.4308 - val_accuracy: 0.9121\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.9339 - val_loss: 0.4488 - val_accuracy: 0.8791\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.8947 - val_loss: 0.3556 - val_accuracy: 0.9231\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.9388 - val_loss: 0.4053 - val_accuracy: 0.9231\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.9278 - val_loss: 0.3478 - val_accuracy: 0.9231\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3172 - accuracy: 0.9315 - val_loss: 0.1945 - val_accuracy: 0.9231\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.9168 - val_loss: 0.3017 - val_accuracy: 0.9231\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9302 - val_loss: 0.4242 - val_accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8972 - val_loss: 0.2112 - val_accuracy: 0.9231\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9364 - val_loss: 0.2923 - val_accuracy: 0.9231\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.9241 - val_loss: 0.2168 - val_accuracy: 0.9231\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.9106 - val_loss: 0.1878 - val_accuracy: 0.9121\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9278 - val_loss: 0.2590 - val_accuracy: 0.9231\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9315 - val_loss: 0.1819 - val_accuracy: 0.9121\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9376 - val_loss: 0.3809 - val_accuracy: 0.9231\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.9217 - val_loss: 0.5094 - val_accuracy: 0.9121\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.9082 - val_loss: 0.2639 - val_accuracy: 0.9231\n",
      "Epoch 75/100\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.4467 - accuracy: 0.9000Restoring model weights from the end of the best epoch: 55.\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2904 - accuracy: 0.9327 - val_loss: 0.3795 - val_accuracy: 0.9231\n",
      "Epoch 00075: early stopping\n",
      "Total training time (sec):  10.660414934158325\n",
      "Best parameters found:  {'hidden_layers': 4, 'hidden_units': 16}\n",
      "Best cross-validated accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Create a KerasClassifier based on the create_model function\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=100, verbose=1)\n",
    "\n",
    "### Inserisci alcuni valori interi separati da virgola tra le parentesi quadre ####\n",
    "param_grid = {\n",
    "    'hidden_layers' : [4],\n",
    "    'hidden_units' : [4,8,16]\n",
    "}\n",
    "###########################################################\n",
    "\n",
    "### Stabilisci il valore di PATIENCE (per esempio 10) ###\n",
    "PATIENCE = 20\n",
    "###########################################################\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n",
    "\n",
    "### Add early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE, restore_best_weights=True)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks= [early_stopping])\n",
    "stop_time = time.time()\n",
    "\n",
    "# Total training time\n",
    "print(\"Total training time (sec): \", stop_time-start_time)\n",
    "# Print the best parameters and corresponding accuracy\n",
    "print(\"Best parameters found: \", grid_result.best_params_)\n",
    "print(\"Best cross-validated accuracy: {:.2f}\".format(grid_result.best_score_))\n",
    "\n",
    "# Salviamo il modello migliore\n",
    "best_model = grid.best_estimator_.model\n",
    "best_model.save('./mlp_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53ac0a",
   "metadata": {},
   "source": [
    "# Usiamo il modello con dei dati mai visti (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62517926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.9842931937172775\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.squeeze(best_model.predict(X_test, batch_size=32) > 0.5)\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e91998",
   "metadata": {},
   "source": [
    "# Stampiamo la confusion matrix\n",
    "Questo ci permette di capire dove sbaglia il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c55ba23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "y_test_binary = (y_test > 0).astype(int)\n",
    "y_pred_binary = (y_pred > 0).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['Benigno', 'DDoS'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
