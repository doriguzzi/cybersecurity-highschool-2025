{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2916704",
   "metadata": {},
   "source": [
    "# Intrusion Detection with Logistic Regression\n",
    "In questo notebook utilizzeremo Logistic Regression per classificare i flussi di traffico di rete come benigni o dannosi. Il modello di Logistic Regression restituisce un valore compreso tra 0 e 1, che rappresenta la probabilità che il flusso in ingresso sia dannoso. Usiamo una soglia fissata a 0,5 per determinare se il flusso di rete è dannoso o meno.\n",
    "Addestreremo un modello di Logistic Regression con traffico di rete benigno e quattro classi di attacchi DDoS dal dataset CIC-DDoS2019 dell’Università del New Brunswick. Il traffico di rete è stato precedentemente pre-elaborato in modo che i pacchetti siano raggruppati in flussi di traffico bidirezionali utilizzando la 5-tupla (IP sorgente, IP destinazione, porta sorgente, porta destinazione, protocollo). Ogni flusso è rappresentato da 21 features (attributi) dell’header dei pacchetti calcolate da un massimo di 1000 pacchetti:\n",
    "\n",
    "| Features           | Logistic Regression model           |\n",
    "|---------------------|--------------------|\n",
    "| timestamp (mean IAT)  <br> packet_length (mean) <br> IP_flags_df (sum) <br> IP_flags_mf (sum) <br> IP_flags_rb (sum) <br> IP_frag_off (sum) <br> protocols (mean) <br> TCP_length (mean) <br> TCP_flags_ack (sum) <br> TCP_flags_cwr (sum) <br> TCP_flags_ece (sum) <br> TCP_flags_fin (sum) <br> TCP_flags_push (sum) <br> TCP_flags_res (sum) <br> TCP_flags_reset (sum) <br> TCP_flags_syn (sum) <br> TCP_flags_urg (sum) <br> TCP_window_size (mean) <br> UDP_length (mean) <br> ICMP_type (mean) <br> Packets (counter) <br>| <img src=\"./logistic_regression_CIC2019.png\" width=\"100%\">  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a046372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Corso di Algoritmi di Machine Learning per la rilevazione di attacchi informatici\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from util_functions import *\n",
    "DATASET_FOLDER = \"../Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf328a43",
   "metadata": {},
   "source": [
    "# Conversione delle labels\n",
    "Nel nostro dataset, le labels assegnate ai flussi hanno un valore numerico che varia da 0 (benigno) a 4 (abbiamo 4 tipi di attacchi). In questo notebook, noi ci occupiamo di classificazione binaria (0/1, cioe' benigno/malevolo) e per cui, dopo aver caricato il dataset dai files, convertiamo tutte le labels > 0 in 1. \n",
    "\n",
    "Questo vuol dire che non ci interessa capire il tipo di attacco, ma solo se c'e' un attacco o meno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc165dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training, validation and test sets\n",
    "feature_names = get_feature_names()\n",
    "target_names = ['benign', 'dns',  'syn', 'udplag', 'webddos'] \n",
    "target_names_full = ['benign', 'dns', 'ldap', 'mssql', 'netbios', 'ntp', 'portmap', 'snmp', 'ssdp', 'syn', 'tftp', 'udp', 'udplag', 'webddos'] \n",
    "X_train, y_train = load_dataset(DATASET_FOLDER + \"/*\" + '-train.hdf5')\n",
    "y_train = np.array([1 if y > 0 else 0 for y in y_train]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1\n",
    "\n",
    "X_val, y_val = load_dataset(DATASET_FOLDER + \"/*\" + '-val.hdf5')\n",
    "y_val = np.array([1 if y > 0 else 0 for y in y_val]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1\n",
    "\n",
    "X_test, y_test = load_dataset(DATASET_FOLDER + \"/*\" + '-test.hdf5')\n",
    "y_test = np.array([1 if y > 0 else 0 for y in y_test]) # classificazione binaria, tutte le labels diverse da 0 le trasformiamo in 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bf8f4",
   "metadata": {},
   "source": [
    "# Implementazione del modello\n",
    "Nella prossima cella, implementiamo il modello di Logistic Regression. \n",
    "Il modello e' creato con una procedura identica a quella usata per creare una rete neurale. L'unica differeza sta nella complessita' del modello. Nel caso di Logistic Regression basta una riga di codice (riga 4). Nel caso di una rete neurale profonda, no. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "def LogRegression(model_name, input_shape):\n",
    "    model = Sequential(name=model_name)\n",
    "    model.add(Dense(1, input_shape=input_shape,activation='sigmoid', name='fc1'))\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def compileModel(model,lr):\n",
    "    #optimizer = SGD(learning_rate=lr, momentum=0.0) # the optimisation algorithm\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])  # here we specify the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff22587",
   "metadata": {},
   "source": [
    "# Model training\n",
    "Nella cella seguente addestriamo il modello di Logistic Regression. L'output del processo di training mostra come l'accuracy del modello tenda a crescere ad ogni iterazione (```epoch```). Questo vuol dire che il modello sta imparando a distiguere i flussi di traffico benigni da quelli malevoli.\n",
    "Lo addestriamo per 100 epoche. E' sufficiente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegression('log_reg', X_train.shape[1:4])\n",
    "compileModel(model,0.001)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53ac0a",
   "metadata": {},
   "source": [
    "# Usiamo il modello con dei dati mai visti (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62517926",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.squeeze(model.predict(X_test, batch_size=32) > 0.5)\n",
    "\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e91998",
   "metadata": {},
   "source": [
    "# Stampiamo la confusion matrix\n",
    "Questo ci permette di capire dove sbaglia il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "y_test_binary = (y_test > 0).astype(int)\n",
    "y_pred_binary = (y_pred > 0).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['Benigno', 'DDoS'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e474ab",
   "metadata": {},
   "source": [
    "# Early stopping\n",
    "Invece di addestrare per un numero pre-definito di epoche, usiamo la tecnica chiamata ```early stopping```. Early stopping controlla l'accuratezza del modello ad ogni epoca. Se l'accuratezza non cresce per un certo numero di epoche (```PATIENCE```), il processo di training si ferma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = LogRegression('log_reg', X_train.shape[1:4])\n",
    "compileModel(model,0.001)\n",
    "\n",
    "PATIENCE = 25 \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=PATIENCE, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Retrain the model with early-stopping\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_val, y_val), verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb81ea",
   "metadata": {},
   "source": [
    "# Stampiamo di nuovo la confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b617fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "y_test_binary = (y_test > 0).astype(int)\n",
    "y_pred_binary = (y_pred > 0).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=['Benigno', 'DDoS'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
